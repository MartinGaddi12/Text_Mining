{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7d1604",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:right;border-radius:5px 5px;\">\n",
    "    <i>Aprender una técnica no es un fin en si mismo, simplemente indica por donde hay que empezar</i><br><b>Proverbio Japonés</b></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8addd52b",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:right;border-radius:5px 5px;\">\n",
    "<i>Material curado y organizado por el Prof. Dr. Hernán D. Merlino</i><br> \n",
    "<i>Retrieval Augmented Generation (RAG)  Versión 2.0 - 2025 Q1</i></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b32fe",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px 5px;\">\n",
    "<strong>_____________________________________________________________</strong></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba67b1b",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:25px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px 5px;\">\n",
    "<strong>R</strong>etrieval <strong>A</strong>ugmented <strong>G</strong>eneration</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edabf0a",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>RAG (Retrieval-Augmented Generation)</strong>\n",
    "combina modelos LLM con recuperación de información externa.<br>\n",
    "Usa bases de datos vectoriales para buscar contexto relevante.<br>\n",
    "Mejora respuestas usando datos más actualizados o específicos de dominio.<br>\n",
    "Ideal para preguntas fuera del conocimiento preentrenado.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe8268",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Pasos</strong><br>\n",
    "1. Retrieve: Convierte la consulta en vector y busca k elementos relevantes<br>\n",
    "2. Augment: Combina consulta y contexto en un prompt extendido<br>\n",
    "3. Generate: Envía el prompt al LLM para generar una respuesta</p>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31055259",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Ejemplo</strong><br>\n",
    "<b><i>Consulta:</i></b> ¿Cuál fue la facturación del mes pasado?<br>\n",
    "<b><i>Retrieve:</i></b> Busca informes financieros en base de datos interna.<br>\n",
    "<b><i>Augment:</i></b> Combina la consulta con el informe más relevante.<br>\n",
    "<b><i>Generate:</i></b> El LLM responde: 'La facturación fue de $1.2M según el reporte del 31/05.'</p>            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be2ca7",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Ventajas</strong><br>\n",
    "Menor costo de entrenamiento comparado con fine-tuning<br>\n",
    "Respuestas más actualizadas y específicas</p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a694f8",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Desventajas</strong><br>\n",
    "Requiere buena infraestructura en produccióng<br>\n",
    "Problemas de transparencia (caja negra)<br>\n",
    "Calidad depende de datos recuperados y precisión de embeddings</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f6ae3",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Cargar librerías</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c04648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec417e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fb51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo se ejecuta la primera vez para instalar la libreria\n",
    "#!conda install -c huggingface transformers=4.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd77fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"H:/HF/MODEL_CACHE\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"H:/HF/MODEL_CACHE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9994cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5049094",
   "metadata": {},
   "source": [
    "<p style=\"font-size:17px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<a href=\"https://huggingface.co/docs/transformers/main_classes/pipelines\" target=\\\"_blank\\\">Pipelines Method</a></p>\n",
    "\n",
    "<p style=\"font-size:17px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<a href=\"https://huggingface.co/docs/transformers/v4.46.0/en/add_new_pipeline\" target=\\\"_blank\\\">How to create a custom pipeline?</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b8552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(task=\"text-generation\",model=\"datificate/gpt2-small-spanish\",device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3372c4",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "device = -1 → fuerza el uso de CPU<BR>\n",
    "device =  0 → usaría el use de GPU (si existiera)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd33a8",
   "metadata": {},
   "source": [
    "<p style=\"font-size:17px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<a href=\"https://huggingface.co/models?pipeline_tag=text-generation&sort=trending&search=spanish\" target=\\\"_blank\\\">Spanish models</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d86c718",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<a href=\"https:///huggingface.co/datificate/gpt2-small-spanish\" target=\\\"_blank\\\">GPT2-small-spanish is a state-of-the-art language model for Spanish based on the GPT-2 small model</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c5be1",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Corpus de documentos</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34789bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"La inteligencia artificial es una tecnología que permite a las máquinas aprender y hacer tareas inteligentes.\",\n",
    "\"El machine learning es una rama de la inteligencia artificial que se enfoca en enseñar a las computadoras mediante datos.\",\n",
    "\"Python es un lenguaje popular para el desarrollo de inteligencia artificial debido a sus bibliotecas como TensorFlow y PyTorch.\",\n",
    "\"El aprendizaje profundo o deep learning es una técnica avanzada de machine learning que usa redes neuronales profundas.\",\n",
    "\"El machine learning es una tecnica de aparendizaje automático.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4a504",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Vectorización</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7597a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "doc_vectors = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10e09f",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Métodos</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d348d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_document(query, vectorizer, doc_vectors):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, doc_vectors)\n",
    "    most_similar_idx = similarities.argmax()\n",
    "    return documents[most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60869151",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def rag_example(query):\n",
    "    document = retrieve_document(query, vectorizer, doc_vectors)\n",
    "    answer = generator(document,  # Con mas contexto: query + document\n",
    "                       max_length=100,\n",
    "                       truncation=True,\n",
    "                       num_return_sequences=1,\n",
    "                       temperature=0.95,\n",
    "                       top_k=50,  \n",
    "                       top_p=0.9)\n",
    "    return answer[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b456820",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong><u>Params</u></strong>:\n",
    "<ul style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<li><i><b>document:</b></i> texto base</li>\n",
    "<li><i><b>max_length:</b></i> genera hasta 100 tokens</li>\n",
    "<li><i><b>num_return_sequences:</b></i> retorna solo un texto</li>\n",
    "<li><i><b>temperature:</b></i> ajusta la creatividad del modelo</li>\n",
    "<li><i><b>top_k y top_p:</b></i> controlan la selección de palabras para una generación más coherente y variada</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14f258",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Pregunta</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bcab490",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿Qué es el machine learning?\"\n",
    "answer = rag_example(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5321db",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:left;border-radius:5px 5px;\">\n",
    "<strong>Respuesta</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ffe0721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El machine learning es una tecnica de aparendizaje automático.\n",
      "\n",
      "La aplicación es muy parecida a la máquina de trabajo, aunque la capacidad de las máquinas de trabajo es menor y el tiempo más rápido que la máquina de trabajo se puede conseguir.\n",
      "\n",
      "Los beneficios de la machine en la automatización son los que reducen el tiempo de trabajo, por lo que la tecnología no necesita de los procesos de búsqueda y procesamiento en su conjunto, ni de búsqueda ni de búsqueda ni de búsqueda\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6151c90",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px 5px;\">\n",
    "<strong>_____________________________________________________________</strong></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab8422",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:15px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px 5px;\">\n",
    "<strong>_____________________________________________________________</strong></p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
