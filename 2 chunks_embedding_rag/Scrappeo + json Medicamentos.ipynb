{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843368ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping A …   72 fármacos.\n",
      "Scraping B …   59 fármacos.\n",
      "Scraping C …   57 fármacos.\n",
      "Scraping D …   50 fármacos.\n",
      "Scraping E …   52 fármacos.\n",
      "Scraping F …   49 fármacos.\n",
      "Scraping G …   46 fármacos.\n",
      "Scraping H …   44 fármacos.\n",
      "Scraping I …   54 fármacos.\n",
      "Scraping J …   37 fármacos.\n",
      "Scraping K …   43 fármacos.\n",
      "Scraping L …   61 fármacos.\n",
      "Scraping M …   49 fármacos.\n",
      "Scraping N …   51 fármacos.\n",
      "Scraping O …   52 fármacos.\n",
      "Scraping P …   51 fármacos.\n",
      "Scraping Q …   27 fármacos.\n",
      "Scraping R …   56 fármacos.\n",
      "Scraping S …   67 fármacos.\n",
      "Scraping T …   68 fármacos.\n",
      "Scraping U …   41 fármacos.\n",
      "Scraping V …   53 fármacos.\n",
      "Scraping W …   24 fármacos.\n",
      "Scraping X …   42 fármacos.\n",
      "Scraping Y …   21 fármacos.\n",
      "Scraping Z …   45 fármacos.\n",
      "\n",
      "✅  Guardado 1271 fármacos en G:\\Mi unidad\\Data_Science\\Data_Science\\Maestría en Explotación de Datos y Gestión del Conocimiento\\Segundo Año\\Introducción al Text Mining\\TP\\Medicamentos.json\n"
     ]
    }
   ],
   "source": [
    "# ── scrape_drugs_com.py ────────────────────────────────────────────────────\n",
    "import json, string, time, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# CONFIGURACIÓN\n",
    "# ------------------------------------------------------------------------\n",
    "BASE_URL   = \"https://www.drugs.com\"\n",
    "# ⇩⇩⇩  ruta absoluta en tu unidad G:\n",
    "OUTPUT_DIR = Path(r\"G:\\Mi unidad\\Data_Science\\Data_Science\\Maestría en Explotación de Datos y Gestión del Conocimiento\\Segundo Año\\Introducción al Text Mining\\TP\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)      # crea la carpeta si no existe\n",
    "OUTPUT     = OUTPUT_DIR / \"Medicamentos.json\"      # archivo final\n",
    "\n",
    "HEADERS    = {\"User-Agent\": \"PharmaScraper/1.0 (+your_email@domain)\"}\n",
    "DELAY_SECS = 1.0          # pausa entre páginas (respeta al servidor)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "def scrape_letter(letter: str) -> list[dict]:\n",
    "    \"\"\"Devuelve [{'name': 'Abacavir', 'url': 'https://…'}, …] para una letra.\"\"\"\n",
    "    url   = f\"{BASE_URL}/alpha/{letter}.html\"\n",
    "    html  = requests.get(url, headers=HEADERS, timeout=15).text\n",
    "    soup  = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    items = []\n",
    "    for a in soup.select(\"ul.ddc-list-column-2 li a\"):\n",
    "        name = a.text.strip()\n",
    "        link = BASE_URL + a[\"href\"]\n",
    "        items.append({\"name\": name, \"url\": link})\n",
    "    return items\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "def main():\n",
    "    all_drugs = []\n",
    "    for letter in string.ascii_lowercase:\n",
    "        try:\n",
    "            print(f\"Scraping {letter.upper()} …\", end=\" \", flush=True)\n",
    "            data = scrape_letter(letter)\n",
    "            all_drugs.extend(data)\n",
    "            print(f\"{len(data):>4} fármacos.\")\n",
    "            time.sleep(DELAY_SECS)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n  ⚠️  Error con {letter}: {e}\", file=sys.stderr)\n",
    "\n",
    "    # Ordena y elimina duplicados\n",
    "    seen, clean = set(), []\n",
    "    for item in sorted(all_drugs, key=lambda d: d[\"name\"].lower()):\n",
    "        key = item[\"name\"].lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            clean.append(item)\n",
    "\n",
    "    OUTPUT.write_text(json.dumps(clean, ensure_ascii=False, indent=2))\n",
    "    print(f\"\\n✅  Guardado {len(clean)} fármacos en {OUTPUT.resolve()}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LucasBrusasca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
